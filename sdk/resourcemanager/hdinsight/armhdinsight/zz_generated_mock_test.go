//go:build go1.16
// +build go1.16

// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License. See License.txt in the project root for license information.
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

package armhdinsight

import (
	"context"
	"fmt"
	"net/http"
	"os"
	"runtime/debug"
	"testing"

	"time"

	"github.com/Azure/azure-sdk-for-go/sdk/azcore"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/arm"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/policy"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
	"github.com/Azure/azure-sdk-for-go/sdk/azidentity"
	"golang.org/x/net/http2"
)

var (
	ctx            context.Context
	subscriptionId string
	cred           azcore.TokenCredential
	err            error
	con            *arm.Connection
	mockHost       string
)

func TestClusters_Create(t *testing.T) {
	// From example Create HDInsight cluster with Autoscale configuration
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	poller, err := client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					ComponentVersion: map[string]*string{
						"Hadoop": to.StringPtr("2.7"),
					},
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("hadoop"),
				},
				ClusterVersion: to.StringPtr("3.6"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("workernode"),
							AutoscaleConfiguration: &Autoscale{
								Capacity: &AutoscaleCapacity{},
								Recurrence: &AutoscaleRecurrence{
									Schedule: []*AutoscaleSchedule{
										{
											Days: []*DaysOfWeek{
												DaysOfWeekMonday.ToPtr(),
												DaysOfWeekTuesday.ToPtr(),
												DaysOfWeekWednesday.ToPtr(),
												DaysOfWeekThursday.ToPtr(),
												DaysOfWeekFriday.ToPtr()},
											TimeAndCapacity: &AutoscaleTimeAndCapacity{
												MaxInstanceCount: to.Int32Ptr(3),
												MinInstanceCount: to.Int32Ptr(3),
												Time:             to.StringPtr("09:00"),
											},
										},
										{
											Days: []*DaysOfWeek{
												DaysOfWeekMonday.ToPtr(),
												DaysOfWeekTuesday.ToPtr(),
												DaysOfWeekWednesday.ToPtr(),
												DaysOfWeekThursday.ToPtr(),
												DaysOfWeekFriday.ToPtr()},
											TimeAndCapacity: &AutoscaleTimeAndCapacity{
												MaxInstanceCount: to.Int32Ptr(6),
												MinInstanceCount: to.Int32Ptr(6),
												Time:             to.StringPtr("18:00"),
											},
										},
										{
											Days: []*DaysOfWeek{
												DaysOfWeekSaturday.ToPtr(),
												DaysOfWeekSunday.ToPtr()},
											TimeAndCapacity: &AutoscaleTimeAndCapacity{
												MaxInstanceCount: to.Int32Ptr(2),
												MinInstanceCount: to.Int32Ptr(2),
												Time:             to.StringPtr("09:00"),
											},
										},
										{
											Days: []*DaysOfWeek{
												DaysOfWeekSaturday.ToPtr(),
												DaysOfWeekSunday.ToPtr()},
											TimeAndCapacity: &AutoscaleTimeAndCapacity{
												MaxInstanceCount: to.Int32Ptr(4),
												MinInstanceCount: to.Int32Ptr(4),
												Time:             to.StringPtr("18:00"),
											},
										}},
									TimeZone: to.StringPtr("China Standard Time"),
								},
							},
							DataDisksGroups: []*DataDisksGroups{},
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D4_V2"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							ScriptActions:         []*ScriptAction{},
							TargetInstanceCount:   to.Int32Ptr(4),
							VirtualNetworkProfile: &VirtualNetworkProfile{},
						}},
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage.blob.core.windows.net"),
							Container: to.StringPtr("hdinsight-autoscale-tes-2019-06-18t05-49-16-591z"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storagekey"),
						}},
				},
				Tier: TierStandard.ToPtr(),
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err := poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create Hadoop cluster with Azure Data Lake Storage Gen 2
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": "true",
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("Hadoop"),
				},
				ClusterVersion: to.StringPtr("3.6"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D3_V2"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D3_V2"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(4),
						},
						{
							Name: to.StringPtr("zookeepernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Small"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						}},
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:       to.StringPtr("mystorage.dfs.core.windows.net"),
							FileSystem: to.StringPtr("default"),
							IsDefault:  to.BoolPtr(true),
							Key:        to.StringPtr("storagekey"),
						}},
				},
				Tier: TierStandard.ToPtr(),
			},
			Tags: map[string]*string{
				"key1": to.StringPtr("val1"),
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create Hadoop on Linux cluster with SSH password
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": "true",
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("Hadoop"),
				},
				ClusterVersion: to.StringPtr("3.5"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D3_V2"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D3_V2"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(4),
						},
						{
							Name: to.StringPtr("zookeepernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Small"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						}},
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage.blob.core.windows.net"),
							Container: to.StringPtr("containername"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storagekey"),
						}},
				},
				Tier: TierStandard.ToPtr(),
			},
			Tags: map[string]*string{
				"key1": to.StringPtr("val1"),
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create Hadoop on Linux cluster with SSH public key
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("Hadoop"),
				},
				ClusterVersion: to.StringPtr("3.5"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D3_V2"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									SSHProfile: &SSHProfile{
										PublicKeys: []*SSHPublicKey{
											{
												CertificateData: to.StringPtr("**********"),
											}},
									},
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D3_V2"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(4),
						},
						{
							Name: to.StringPtr("zookeepernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Small"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						}},
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage.blob.core.windows.net"),
							Container: to.StringPtr("containername"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storagekey"),
						}},
				},
				Tier: TierStandard.ToPtr(),
			},
			Tags: map[string]*string{
				"key1": to.StringPtr("val1"),
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create Kafka cluster with Kafka Rest Proxy
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					ComponentVersion: map[string]*string{
						"Kafka": to.StringPtr("2.1"),
					},
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("kafka"),
				},
				ClusterVersion: to.StringPtr("4.0"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Large"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						},
						{
							Name: to.StringPtr("workernode"),
							DataDisksGroups: []*DataDisksGroups{
								{
									DisksPerNode: to.Int32Ptr(8),
								}},
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Large"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						},
						{
							Name: to.StringPtr("zookeepernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Small"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						},
						{
							Name: to.StringPtr("kafkamanagementnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D4_v2"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("kafkauser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						}},
				},
				KafkaRestProperties: &KafkaRestProperties{
					ClientGroupInfo: &ClientGroupInfo{
						GroupID:   to.StringPtr("00000000-0000-0000-0000-111111111111"),
						GroupName: to.StringPtr("Kafka security group name"),
					},
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage.blob.core.windows.net"),
							Container: to.StringPtr("containername"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storagekey"),
						}},
				},
				Tier: TierStandard.ToPtr(),
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create Secure Hadoop cluster
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("Hadoop"),
				},
				ClusterVersion: to.StringPtr("3.5"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D3_V2"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									SSHProfile: &SSHProfile{
										PublicKeys: []*SSHPublicKey{
											{
												CertificateData: to.StringPtr("**********"),
											}},
									},
									Username: to.StringPtr("sshuser"),
								},
							},
							ScriptActions:       []*ScriptAction{},
							TargetInstanceCount: to.Int32Ptr(2),
							VirtualNetworkProfile: &VirtualNetworkProfile{
								ID:     to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname"),
								Subnet: to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname/subnets/vnetsubnet"),
							},
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D3_V2"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									SSHProfile: &SSHProfile{
										PublicKeys: []*SSHPublicKey{
											{
												CertificateData: to.StringPtr("**********"),
											}},
									},
									Username: to.StringPtr("sshuser"),
								},
							},
							ScriptActions:       []*ScriptAction{},
							TargetInstanceCount: to.Int32Ptr(4),
							VirtualNetworkProfile: &VirtualNetworkProfile{
								ID:     to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname"),
								Subnet: to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname/subnets/vnetsubnet"),
							},
						},
						{
							Name: to.StringPtr("zookeepernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Small"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									SSHProfile: &SSHProfile{
										PublicKeys: []*SSHPublicKey{
											{
												CertificateData: to.StringPtr("**********"),
											}},
									},
									Username: to.StringPtr("sshuser"),
								},
							},
							ScriptActions:       []*ScriptAction{},
							TargetInstanceCount: to.Int32Ptr(3),
							VirtualNetworkProfile: &VirtualNetworkProfile{
								ID:     to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname"),
								Subnet: to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname/subnets/vnetsubnet"),
							},
						}},
				},
				OSType: OSTypeLinux.ToPtr(),
				SecurityProfile: &SecurityProfile{
					ClusterUsersGroupDNs: []*string{
						to.StringPtr("hdiusers")},
					DirectoryType:      DirectoryTypeActiveDirectory.ToPtr(),
					Domain:             to.StringPtr("DomainName"),
					DomainUserPassword: to.StringPtr("**********"),
					DomainUsername:     to.StringPtr("DomainUsername"),
					LdapsUrls: []*string{
						to.StringPtr("ldaps://10.10.0.4:636")},
					OrganizationalUnitDN: to.StringPtr("OU=Hadoop,DC=hdinsight,DC=test"),
				},
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage.blob.core.windows.net"),
							Container: to.StringPtr("containername"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storage account key"),
						}},
				},
				Tier: TierPremium.ToPtr(),
			},
			Tags: map[string]*string{
				"key1": to.StringPtr("val1"),
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create Spark on Linux Cluster with SSH password
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					ComponentVersion: map[string]*string{
						"Spark": to.StringPtr("2.0"),
					},
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("Spark"),
				},
				ClusterVersion: to.StringPtr("3.5"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D12_V2"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D4_V2"),
							},
							MinInstanceCount: to.Int32Ptr(1),
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(4),
						}},
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage.blob.core.windows.net"),
							Container: to.StringPtr("containername"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storageapikey*"),
						}},
				},
				Tier: TierStandard.ToPtr(),
			},
			Tags: map[string]*string{
				"key1": to.StringPtr("val1"),
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create cluster with TLS 1.2
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("Hadoop"),
				},
				ClusterVersion: to.StringPtr("3.6"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Large"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Large"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						},
						{
							Name: to.StringPtr("zookeepernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Small"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						}},
				},
				MinSupportedTLSVersion: to.StringPtr("1.2"),
				OSType:                 OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage.blob.core.windows.net"),
							Container: to.StringPtr("default8525"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storagekey"),
						}},
				},
				Tier: TierStandard.ToPtr(),
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create cluster with availability zones
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					Configurations: map[string]interface{}{
						"ambari-conf": map[string]interface{}{
							"database-name":          "{ambari database name}",
							"database-server":        "{sql server name}.database.windows.net",
							"database-user-name":     "**********",
							"database-user-password": "**********",
						},
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
						"hive-env": map[string]interface{}{
							"hive_database":                       "Existing MSSQL Server database with SQL authentication",
							"hive_database_name":                  "{hive metastore name}",
							"hive_database_type":                  "mssql",
							"hive_existing_mssql_server_database": "{hive metastore name}",
							"hive_existing_mssql_server_host":     "{sql server name}.database.windows.net",
							"hive_hostname":                       "{sql server name}.database.windows.net",
						},
						"hive-site": map[string]interface{}{
							"javax.jdo.option.ConnectionDriverName": "com.microsoft.sqlserver.jdbc.SQLServerDriver",
							"javax.jdo.option.ConnectionPassword":   "**********!",
							"javax.jdo.option.ConnectionURL":        "jdbc:sqlserver://{sql server name}.database.windows.net;database={hive metastore name};encrypt=true;trustServerCertificate=true;create=false;loginTimeout=300;sendStringParametersAsUnicode=true;prepareSQL=0",
							"javax.jdo.option.ConnectionUserName":   "**********",
						},
						"oozie-env": map[string]interface{}{
							"oozie_database":                       "Existing MSSQL Server database with SQL authentication",
							"oozie_database_name":                  "{oozie metastore name}",
							"oozie_database_type":                  "mssql",
							"oozie_existing_mssql_server_database": "{oozie metastore name}",
							"oozie_existing_mssql_server_host":     "{sql server name}.database.windows.net",
							"oozie_hostname":                       "{sql server name}.database.windows.net",
						},
						"oozie-site": map[string]interface{}{
							"oozie.db.schema.name":                   "oozie",
							"oozie.service.JPAService.jdbc.driver":   "com.microsoft.sqlserver.jdbc.SQLServerDriver",
							"oozie.service.JPAService.jdbc.password": "**********",
							"oozie.service.JPAService.jdbc.url":      "jdbc:sqlserver://{sql server name}.database.windows.net;database={oozie metastore name};encrypt=true;trustServerCertificate=true;create=false;loginTimeout=300;sendStringParametersAsUnicode=true;prepareSQL=0",
							"oozie.service.JPAService.jdbc.username": "**********",
						},
					},
					Kind: to.StringPtr("hadoop"),
				},
				ClusterVersion: to.StringPtr("3.6"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("standard_d3"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									SSHProfile: &SSHProfile{
										PublicKeys: []*SSHPublicKey{
											{
												CertificateData: to.StringPtr("**********"),
											}},
									},
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
							VirtualNetworkProfile: &VirtualNetworkProfile{
								ID:     to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname"),
								Subnet: to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname/subnets/vnetsubnet"),
							},
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("standard_d3"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									SSHProfile: &SSHProfile{
										PublicKeys: []*SSHPublicKey{
											{
												CertificateData: to.StringPtr("**********"),
											}},
									},
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
							VirtualNetworkProfile: &VirtualNetworkProfile{
								ID:     to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname"),
								Subnet: to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname/subnets/vnetsubnet"),
							},
						}},
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage"),
							Container: to.StringPtr("containername"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storage account key"),
						}},
				},
			},
			Zones: []*string{
				to.StringPtr("1")},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create cluster with compute isolation properties
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("hadoop"),
				},
				ClusterVersion: to.StringPtr("3.6"),
				ComputeIsolationProperties: &ComputeIsolationProperties{
					EnableComputeIsolation: to.BoolPtr(true),
					HostSKU:                to.StringPtr("null"),
				},
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("standard_d3"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									SSHProfile: &SSHProfile{
										PublicKeys: []*SSHPublicKey{
											{
												CertificateData: to.StringPtr("**********"),
											}},
									},
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("standard_d3"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									SSHProfile: &SSHProfile{
										PublicKeys: []*SSHPublicKey{
											{
												CertificateData: to.StringPtr("**********"),
											}},
									},
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						}},
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage"),
							Container: to.StringPtr("containername"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storage account key"),
						}},
				},
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create cluster with encryption at host
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("Hadoop"),
				},
				ClusterVersion: to.StringPtr("3.6"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_DS14_v2"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_DS14_v2"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						},
						{
							Name: to.StringPtr("zookeepernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_DS14_v2"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						}},
				},
				DiskEncryptionProperties: &DiskEncryptionProperties{
					EncryptionAtHost: to.BoolPtr(true),
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage.blob.core.windows.net"),
							Container: to.StringPtr("default8525"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storagekey"),
						}},
				},
				Tier: TierStandard.ToPtr(),
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create cluster with encryption in transit
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("Hadoop"),
				},
				ClusterVersion: to.StringPtr("3.6"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Large"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Large"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						},
						{
							Name: to.StringPtr("zookeepernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Small"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(3),
						}},
				},
				EncryptionInTransitProperties: &EncryptionInTransitProperties{
					IsEncryptionInTransitEnabled: to.BoolPtr(true),
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage.blob.core.windows.net"),
							Container: to.StringPtr("default8525"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storagekey"),
						}},
				},
				Tier: TierStandard.ToPtr(),
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Create cluster with network properties
	poller, err = client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		ClusterCreateParametersExtended{
			Properties: &ClusterCreateProperties{
				ClusterDefinition: &ClusterDefinition{
					Configurations: map[string]interface{}{
						"gateway": map[string]interface{}{
							"restAuthCredential.isEnabled": true,
							"restAuthCredential.password":  "**********",
							"restAuthCredential.username":  "admin",
						},
					},
					Kind: to.StringPtr("hadoop"),
				},
				ClusterVersion: to.StringPtr("3.6"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("headnode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("standard_d3"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									SSHProfile: &SSHProfile{
										PublicKeys: []*SSHPublicKey{
											{
												CertificateData: to.StringPtr("**********"),
											}},
									},
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
							VirtualNetworkProfile: &VirtualNetworkProfile{
								ID:     to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname"),
								Subnet: to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname/subnets/vnetsubnet"),
							},
						},
						{
							Name: to.StringPtr("workernode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("standard_d3"),
							},
							OSProfile: &OsProfile{
								LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
									Password: to.StringPtr("**********"),
									SSHProfile: &SSHProfile{
										PublicKeys: []*SSHPublicKey{
											{
												CertificateData: to.StringPtr("**********"),
											}},
									},
									Username: to.StringPtr("sshuser"),
								},
							},
							TargetInstanceCount: to.Int32Ptr(2),
							VirtualNetworkProfile: &VirtualNetworkProfile{
								ID:     to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname"),
								Subnet: to.StringPtr("/subscriptions/subId/resourceGroups/rg/providers/Microsoft.Network/virtualNetworks/vnetname/subnets/vnetsubnet"),
							},
						}},
				},
				NetworkProperties: &NetworkProperties{
					PrivateLink:                PrivateLinkEnabled.ToPtr(),
					ResourceProviderConnection: ResourceProviderConnectionOutbound.ToPtr(),
				},
				OSType: OSTypeLinux.ToPtr(),
				StorageProfile: &StorageProfile{
					Storageaccounts: []*StorageAccount{
						{
							Name:      to.StringPtr("mystorage"),
							Container: to.StringPtr("containername"),
							IsDefault: to.BoolPtr(true),
							Key:       to.StringPtr("storage account key"),
						}},
				},
			},
		},
		&ClustersBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}
}

func TestClusters_Update(t *testing.T) {
	// From example Patch HDInsight Linux clusters
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	res, err := client.Update(ctx,
		"rg1",
		"cluster1",
		ClusterPatchParameters{
			Tags: map[string]*string{
				"key1": to.StringPtr("val1"),
				"key2": to.StringPtr("val2"),
			},
		},
		&ClustersUpdateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}
}

func TestClusters_Delete(t *testing.T) {
	// From example Delete Hadoop on Linux cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	poller, err := client.BeginDelete(ctx,
		"rg1",
		"cluster1",
		&ClustersBeginDeleteOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestClusters_Get(t *testing.T) {
	// From example Get Hadoop on Linux cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	res, err := client.Get(ctx,
		"rg1",
		"cluster1",
		&ClustersGetOptions{})
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}

	// From example Get Spark on Linux cluster
	res, err = client.Get(ctx,
		"rg1",
		"cluster1",
		&ClustersGetOptions{})
	if err != nil {
		t.Fatal(err)
	}
	if res.Cluster.ID == nil {
		t.Fatal("Cluster.ID should not be nil!")
	}
}

func TestClusters_ListByResourceGroup(t *testing.T) {
	// From example Get All Hadoop on Linux clusters in a resource group
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	pager := client.ListByResourceGroup("rg1",
		&ClustersListByResourceGroupOptions{})
	for pager.NextPage(ctx) {
		if err := pager.Err(); err != nil {
			t.Fatalf("failed to advance page: %v", err)
		}
		for _, v := range pager.PageResponse().Value {
			fmt.Printf("Cluster.ID: %s\n", *v.ID)
			if v.ID == nil {
				t.Fatal("Cluster.ID should not be nil!")
			}
		}
	}
}

func TestClusters_Resize(t *testing.T) {
	// From example Resize the worker nodes for a Hadoop on Linux cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	poller, err := client.BeginResize(ctx,
		"rg1",
		"cluster1",
		RoleNameWorkernode,
		ClusterResizeParameters{
			TargetInstanceCount: to.Int32Ptr(10),
		},
		&ClustersBeginResizeOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestClusters_UpdateAutoScaleConfiguration(t *testing.T) {
	// From example Disable Autoscale for the HDInsight cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	poller, err := client.BeginUpdateAutoScaleConfiguration(ctx,
		"rg1",
		"cluster1",
		RoleNameWorkernode,
		AutoscaleConfigurationUpdateParameter{},
		&ClustersBeginUpdateAutoScaleConfigurationOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}

	// From example Enable or Update Autoscale with the load based configuration for HDInsight cluster
	poller, err = client.BeginUpdateAutoScaleConfiguration(ctx,
		"rg1",
		"cluster1",
		RoleNameWorkernode,
		AutoscaleConfigurationUpdateParameter{
			Autoscale: &Autoscale{
				Capacity: &AutoscaleCapacity{
					MaxInstanceCount: to.Int32Ptr(5),
					MinInstanceCount: to.Int32Ptr(3),
				},
			},
		},
		&ClustersBeginUpdateAutoScaleConfigurationOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}

	// From example Enable or Update Autoscale with the schedule based configuration for HDInsight cluster
	poller, err = client.BeginUpdateAutoScaleConfiguration(ctx,
		"rg1",
		"cluster1",
		RoleNameWorkernode,
		AutoscaleConfigurationUpdateParameter{
			Autoscale: &Autoscale{
				Recurrence: &AutoscaleRecurrence{
					Schedule: []*AutoscaleSchedule{
						{
							Days: []*DaysOfWeek{
								DaysOfWeekThursday.ToPtr()},
							TimeAndCapacity: &AutoscaleTimeAndCapacity{
								MaxInstanceCount: to.Int32Ptr(4),
								MinInstanceCount: to.Int32Ptr(4),
								Time:             to.StringPtr("16:00"),
							},
						}},
					TimeZone: to.StringPtr("China Standard Time"),
				},
			},
		},
		&ClustersBeginUpdateAutoScaleConfigurationOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestClusters_List(t *testing.T) {
	// From example Get All Hadoop on Linux clusters
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	pager := client.List(&ClustersListOptions{})
	for pager.NextPage(ctx) {
		if err := pager.Err(); err != nil {
			t.Fatalf("failed to advance page: %v", err)
		}
		for _, v := range pager.PageResponse().Value {
			fmt.Printf("Cluster.ID: %s\n", *v.ID)
			if v.ID == nil {
				t.Fatal("Cluster.ID should not be nil!")
			}
		}
	}
}

func TestClusters_RotateDiskEncryptionKey(t *testing.T) {
	// From example Rotate disk encryption key of the specified HDInsight cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	poller, err := client.BeginRotateDiskEncryptionKey(ctx,
		"rg1",
		"cluster1",
		ClusterDiskEncryptionParameters{
			KeyName:    to.StringPtr("newkeyname"),
			KeyVersion: to.StringPtr("newkeyversion"),
			VaultURI:   to.StringPtr("https://newkeyvault.vault.azure.net/"),
		},
		&ClustersBeginRotateDiskEncryptionKeyOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestClusters_GetGatewaySettings(t *testing.T) {
	// From example Get HTTP settings
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	_, err := client.GetGatewaySettings(ctx,
		"rg1",
		"cluster1",
		&ClustersGetGatewaySettingsOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestClusters_UpdateGatewaySettings(t *testing.T) {
	// From example Enable HTTP connectivity
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	poller, err := client.BeginUpdateGatewaySettings(ctx,
		"rg1",
		"cluster1",
		UpdateGatewaySettingsParameters{
			IsCredentialEnabled: to.BoolPtr(true),
			Password:            to.StringPtr("**********"),
			UserName:            to.StringPtr("hadoop"),
		},
		&ClustersBeginUpdateGatewaySettingsOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestClusters_GetAzureAsyncOperationStatus(t *testing.T) {
	// From example Get Async Operation Status of Creating Cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	_, err := client.GetAzureAsyncOperationStatus(ctx,
		"rg1",
		"cluster1",
		"CF938302-6B4D-44A0-A6D2-C0D67E847AEC",
		&ClustersGetAzureAsyncOperationStatusOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestClusters_UpdateIdentityCertificate(t *testing.T) {
	// From example Update cluster identity certificate
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	poller, err := client.BeginUpdateIdentityCertificate(ctx,
		"rg1",
		"cluster1",
		UpdateClusterIdentityCertificateParameters{
			ApplicationID:       to.StringPtr("applicationId"),
			Certificate:         to.StringPtr("base64encodedcertificate"),
			CertificatePassword: to.StringPtr("**********"),
		},
		&ClustersBeginUpdateIdentityCertificateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestClusters_ExecuteScriptActions(t *testing.T) {
	// From example Execute script action on HDInsight cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewClustersClient(con,
		"subid")
	poller, err := client.BeginExecuteScriptActions(ctx,
		"rg1",
		"cluster1",
		ExecuteScriptActionParameters{
			PersistOnSuccess: to.BoolPtr(false),
			ScriptActions: []*RuntimeScriptAction{
				{
					Name:       to.StringPtr("Test"),
					Parameters: to.StringPtr(""),
					Roles: []*string{
						to.StringPtr("headnode"),
						to.StringPtr("workernode")},
					URI: to.StringPtr("http://testurl.com/install.ssh"),
				}},
		},
		&ClustersBeginExecuteScriptActionsOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestApplications_ListByCluster(t *testing.T) {
	// From example Get All Applications for an HDInsight cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewApplicationsClient(con,
		"subid")
	pager := client.ListByCluster("rg1",
		"cluster1",
		&ApplicationsListByClusterOptions{})
	for pager.NextPage(ctx) {
		if err := pager.Err(); err != nil {
			t.Fatalf("failed to advance page: %v", err)
		}
		for _, v := range pager.PageResponse().Value {
			fmt.Printf("Application.ID: %s\n", *v.ID)
			if v.ID == nil {
				t.Fatal("Application.ID should not be nil!")
			}
		}
	}
}

func TestApplications_Get(t *testing.T) {
	// From example Get application on HDInsight cluster creation in progress
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewApplicationsClient(con,
		"subid")
	res, err := client.Get(ctx,
		"rg1",
		"cluster1",
		"app",
		&ApplicationsGetOptions{})
	if err != nil {
		t.Fatal(err)
	}
	if res.Application.ID == nil {
		t.Fatal("Application.ID should not be nil!")
	}

	// From example Get application on HDInsight cluster successfully created.
	res, err = client.Get(ctx,
		"rg1",
		"cluster1",
		"app",
		&ApplicationsGetOptions{})
	if err != nil {
		t.Fatal(err)
	}
	if res.Application.ID == nil {
		t.Fatal("Application.ID should not be nil!")
	}
}

func TestApplications_Create(t *testing.T) {
	// From example Create Application
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewApplicationsClient(con,
		"subid")
	poller, err := client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		"hue",
		Application{
			Properties: &ApplicationProperties{
				ApplicationType: to.StringPtr("CustomApplication"),
				ComputeProfile: &ComputeProfile{
					Roles: []*Role{
						{
							Name: to.StringPtr("edgenode"),
							HardwareProfile: &HardwareProfile{
								VMSize: to.StringPtr("Standard_D12_v2"),
							},
							TargetInstanceCount: to.Int32Ptr(1),
						}},
				},
				Errors: []*Errors{},
				HTTPSEndpoints: []*ApplicationGetHTTPSEndpoint{
					{
						AccessModes: []*string{
							to.StringPtr("WebPage")},
						DestinationPort: to.Int32Ptr(20000),
						SubDomainSuffix: to.StringPtr("dss"),
					}},
				InstallScriptActions: []*RuntimeScriptAction{
					{
						Name:       to.StringPtr("app-install-app1"),
						Parameters: to.StringPtr("-version latest -port 20000"),
						Roles: []*string{
							to.StringPtr("edgenode")},
						URI: to.StringPtr("https://.../install.sh"),
					}},
				UninstallScriptActions: []*RuntimeScriptAction{},
			},
		},
		&ApplicationsBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err := poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.Application.ID == nil {
		t.Fatal("Application.ID should not be nil!")
	}
}

func TestApplications_Delete(t *testing.T) {
	// From example Delete Application from HDInsight cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewApplicationsClient(con,
		"subid")
	poller, err := client.BeginDelete(ctx,
		"rg1",
		"cluster1",
		"hue",
		&ApplicationsBeginDeleteOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestApplications_GetAzureAsyncOperationStatus(t *testing.T) {
	// From example Get the azure async operation status.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewApplicationsClient(con,
		"subid")
	_, err := client.GetAzureAsyncOperationStatus(ctx,
		"rg1",
		"cluster1",
		"app",
		"CF938302-6B4D-44A0-A6D2-C0D67E847AEC",
		&ApplicationsGetAzureAsyncOperationStatusOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestLocations_GetCapabilities(t *testing.T) {
	// From example Get the subscription capabilities for specific location
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewLocationsClient(con,
		"subid")
	_, err := client.GetCapabilities(ctx,
		"West US",
		&LocationsGetCapabilitiesOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestLocations_ListUsages(t *testing.T) {
	// From example Get the subscription usages for specific location
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewLocationsClient(con,
		"subid")
	_, err := client.ListUsages(ctx,
		"West US",
		&LocationsListUsagesOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestLocations_ListBillingSpecs(t *testing.T) {
	// From example Get the subscription billingSpecs for the specified location
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewLocationsClient(con,
		"subid")
	_, err := client.ListBillingSpecs(ctx,
		"East US 2",
		&LocationsListBillingSpecsOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestLocations_GetAzureAsyncOperationStatus(t *testing.T) {
	// From example Gets the azure async operation status.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewLocationsClient(con,
		"subid")
	_, err := client.GetAzureAsyncOperationStatus(ctx,
		"East US 2",
		"8a0348f4-8a85-4ec2-abe0-03b26104a9a0-0",
		&LocationsGetAzureAsyncOperationStatusOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestLocations_CheckNameAvailability(t *testing.T) {
	// From example Get the subscription usages for specific location
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewLocationsClient(con,
		"subid")
	_, err := client.CheckNameAvailability(ctx,
		"westus",
		NameAvailabilityCheckRequestParameters{
			Name: to.StringPtr("test123"),
			Type: to.StringPtr("clusters"),
		},
		&LocationsCheckNameAvailabilityOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestLocations_ValidateClusterCreateRequest(t *testing.T) {
	// From example Get the subscription usages for specific location
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewLocationsClient(con,
		"subid")
	_, err := client.ValidateClusterCreateRequest(ctx,
		"southcentralus",
		ClusterCreateRequestValidationParameters{
			ClusterCreateParametersExtended: ClusterCreateParametersExtended{
				Location: to.StringPtr("southcentralus"),
				Properties: &ClusterCreateProperties{
					ClusterDefinition: &ClusterDefinition{
						ComponentVersion: map[string]*string{
							"Spark": to.StringPtr("2.4"),
						},
						Configurations: map[string]interface{}{
							"gateway": map[string]interface{}{
								"restAuthCredential.isEnabled": true,
								"restAuthCredential.password":  "**********",
								"restAuthCredential.username":  "admin",
							},
						},
						Kind: to.StringPtr("spark"),
					},
					ClusterVersion: to.StringPtr("4.0"),
					ComputeProfile: &ComputeProfile{
						Roles: []*Role{
							{
								Name:                   to.StringPtr("headnode"),
								AutoscaleConfiguration: &Autoscale{},
								DataDisksGroups:        []*DataDisksGroups{},
								HardwareProfile: &HardwareProfile{
									VMSize: to.StringPtr("Standard_E8_V3"),
								},
								MinInstanceCount: to.Int32Ptr(1),
								OSProfile: &OsProfile{
									LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
										Password: to.StringPtr("********"),
										Username: to.StringPtr("sshuser"),
									},
								},
								ScriptActions:         []*ScriptAction{},
								TargetInstanceCount:   to.Int32Ptr(2),
								VirtualNetworkProfile: &VirtualNetworkProfile{},
							},
							{
								Name:                   to.StringPtr("workernode"),
								AutoscaleConfiguration: &Autoscale{},
								DataDisksGroups:        []*DataDisksGroups{},
								HardwareProfile: &HardwareProfile{
									VMSize: to.StringPtr("Standard_E8_V3"),
								},
								OSProfile: &OsProfile{
									LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
										Password: to.StringPtr("********"),
										Username: to.StringPtr("sshuser"),
									},
								},
								ScriptActions:         []*ScriptAction{},
								TargetInstanceCount:   to.Int32Ptr(4),
								VirtualNetworkProfile: &VirtualNetworkProfile{},
							},
							{
								Name:                   to.StringPtr("zookeepernode"),
								AutoscaleConfiguration: &Autoscale{},
								DataDisksGroups:        []*DataDisksGroups{},
								HardwareProfile: &HardwareProfile{
									VMSize: to.StringPtr("Standard_D13_V2"),
								},
								MinInstanceCount: to.Int32Ptr(1),
								OSProfile: &OsProfile{
									LinuxOperatingSystemProfile: &LinuxOperatingSystemProfile{
										Password: to.StringPtr("**********"),
										Username: to.StringPtr("sshuser"),
									},
								},
								ScriptActions:         []*ScriptAction{},
								TargetInstanceCount:   to.Int32Ptr(3),
								VirtualNetworkProfile: &VirtualNetworkProfile{},
							}},
					},
					MinSupportedTLSVersion: to.StringPtr("1.2"),
					OSType:                 OSTypeLinux.ToPtr(),
					StorageProfile: &StorageProfile{
						Storageaccounts: []*StorageAccount{
							{
								Name:       to.StringPtr("storagename.blob.core.windows.net"),
								Container:  to.StringPtr("contianername"),
								IsDefault:  to.BoolPtr(true),
								Key:        to.StringPtr("*******"),
								ResourceID: to.StringPtr("/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/rg1/providers/Microsoft.Storage/storageAccounts/storagename"),
							}},
					},
					Tier: TierStandard.ToPtr(),
				},
				Tags: map[string]*string{},
			},
			Name:               to.StringPtr("testclustername"),
			Type:               to.StringPtr("Microsoft.HDInsight/clusters"),
			FetchAaddsResource: to.BoolPtr(false),
			TenantID:           to.StringPtr("00000000-0000-0000-0000-000000000000"),
		},
		&LocationsValidateClusterCreateRequestOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestConfigurations_List(t *testing.T) {
	// From example Get all configuration information
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewConfigurationsClient(con,
		"subid")
	_, err := client.List(ctx,
		"rg1",
		"cluster1",
		&ConfigurationsListOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestConfigurations_Update(t *testing.T) {
	// From example Disable HTTP connectivity
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewConfigurationsClient(con,
		"subid")
	poller, err := client.BeginUpdate(ctx,
		"rg1",
		"cluster1",
		"gateway",
		map[string]*string{
			"restAuthCredential.isEnabled": to.StringPtr("false"),
		},
		&ConfigurationsBeginUpdateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}

	// From example Enable HTTP connectivity
	poller, err = client.BeginUpdate(ctx,
		"rg1",
		"cluster1",
		"gateway",
		map[string]*string{
			"restAuthCredential.isEnabled": to.StringPtr("true"),
			"restAuthCredential.password":  to.StringPtr("**********"),
			"restAuthCredential.username":  to.StringPtr("hadoop"),
		},
		&ConfigurationsBeginUpdateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestConfigurations_Get(t *testing.T) {
	// From example Get Core site settings
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewConfigurationsClient(con,
		"subid")
	_, err := client.Get(ctx,
		"rg1",
		"cluster1",
		"core-site",
		&ConfigurationsGetOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestExtensions_EnableMonitoring(t *testing.T) {
	// From example Enable cluster monitoring
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewExtensionsClient(con,
		"subid")
	poller, err := client.BeginEnableMonitoring(ctx,
		"rg1",
		"cluster1",
		ClusterMonitoringRequest{
			PrimaryKey:  to.StringPtr("**********"),
			WorkspaceID: to.StringPtr("a2090ead-8c9f-4fba-b70e-533e3e003163"),
		},
		&ExtensionsBeginEnableMonitoringOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestExtensions_GetMonitoringStatus(t *testing.T) {
	// From example Enable cluster monitoring
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewExtensionsClient(con,
		"subid")
	_, err := client.GetMonitoringStatus(ctx,
		"rg1",
		"cluster1",
		&ExtensionsGetMonitoringStatusOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestExtensions_DisableMonitoring(t *testing.T) {
	// From example Enable cluster monitoring
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewExtensionsClient(con,
		"subid")
	poller, err := client.BeginDisableMonitoring(ctx,
		"rg1",
		"cluster1",
		&ExtensionsBeginDisableMonitoringOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestExtensions_EnableAzureMonitor(t *testing.T) {
	// From example Enable cluster monitoring
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewExtensionsClient(con,
		"subid")
	poller, err := client.BeginEnableAzureMonitor(ctx,
		"rg1",
		"cluster1",
		AzureMonitorRequest{
			PrimaryKey:  to.StringPtr("**********"),
			WorkspaceID: to.StringPtr("a2090ead-8c9f-4fba-b70e-533e3e003163"),
		},
		&ExtensionsBeginEnableAzureMonitorOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestExtensions_GetAzureMonitorStatus(t *testing.T) {
	// From example Enable cluster monitoring
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewExtensionsClient(con,
		"subid")
	_, err := client.GetAzureMonitorStatus(ctx,
		"rg1",
		"cluster1",
		&ExtensionsGetAzureMonitorStatusOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestExtensions_DisableAzureMonitor(t *testing.T) {
	// From example Enable cluster monitoring
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewExtensionsClient(con,
		"subid")
	poller, err := client.BeginDisableAzureMonitor(ctx,
		"rg1",
		"cluster1",
		&ExtensionsBeginDisableAzureMonitorOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestExtensions_Create(t *testing.T) {
	// From example Create a monitoring extension on Hadoop Linux cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewExtensionsClient(con,
		"subid")
	poller, err := client.BeginCreate(ctx,
		"rg1",
		"cluster1",
		"clustermonitoring",
		Extension{
			PrimaryKey:  to.StringPtr("**********"),
			WorkspaceID: to.StringPtr("a2090ead-8c9f-4fba-b70e-533e3e003163"),
		},
		&ExtensionsBeginCreateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestExtensions_Get(t *testing.T) {
	// From example Get an extension
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewExtensionsClient(con,
		"subid")
	_, err := client.Get(ctx,
		"rg1",
		"cluster1",
		"clustermonitoring",
		&ExtensionsGetOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestExtensions_Delete(t *testing.T) {
	// From example Delete an extension
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewExtensionsClient(con,
		"subid")
	poller, err := client.BeginDelete(ctx,
		"rg1",
		"cluster1",
		"clustermonitoring",
		&ExtensionsBeginDeleteOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestExtensions_GetAzureAsyncOperationStatus(t *testing.T) {
	// From example Gets the azure async operation status.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewExtensionsClient(con,
		"subid")
	_, err := client.GetAzureAsyncOperationStatus(ctx,
		"rg1",
		"cluster1",
		"azuremonitor",
		"CF938302-6B4D-44A0-A6D2-C0D67E847AEC",
		&ExtensionsGetAzureAsyncOperationStatusOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestScriptActions_Delete(t *testing.T) {
	// From example Delete a script action on HDInsight cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewScriptActionsClient(con,
		"subid")
	_, err := client.Delete(ctx,
		"rg1",
		"cluster1",
		"scriptName",
		&ScriptActionsDeleteOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestScriptActions_ListByCluster(t *testing.T) {
	// From example List all persisted script actions for the given cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewScriptActionsClient(con,
		"subid")
	pager := client.ListByCluster("rg1",
		"cluster1",
		&ScriptActionsListByClusterOptions{})
	for pager.NextPage(ctx) {
		if err := pager.Err(); err != nil {
			t.Fatalf("failed to advance page: %v", err)
		}
	}
}

func TestScriptActions_GetExecutionDetail(t *testing.T) {
	// From example Get script execution history by script id
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewScriptActionsClient(con,
		"subid")
	_, err := client.GetExecutionDetail(ctx,
		"rg1",
		"cluster1",
		"391145124054712",
		&ScriptActionsGetExecutionDetailOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestScriptActions_GetExecutionAsyncOperationStatus(t *testing.T) {
	// From example Gets the async execution operation status.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewScriptActionsClient(con,
		"subid")
	_, err := client.GetExecutionAsyncOperationStatus(ctx,
		"rg1",
		"cluster1",
		"CF938302-6B4D-44A0-A6D2-C0D67E847AEC",
		&ScriptActionsGetExecutionAsyncOperationStatusOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestScriptExecutionHistory_ListByCluster(t *testing.T) {
	// From example Get Script Execution History List
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewScriptExecutionHistoryClient(con,
		"subid")
	pager := client.ListByCluster("rg1",
		"cluster1",
		&ScriptExecutionHistoryListByClusterOptions{})
	for pager.NextPage(ctx) {
		if err := pager.Err(); err != nil {
			t.Fatalf("failed to advance page: %v", err)
		}
	}
}

func TestScriptExecutionHistory_Promote(t *testing.T) {
	// From example Promote a script action on HDInsight cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewScriptExecutionHistoryClient(con,
		"subid")
	_, err := client.Promote(ctx,
		"rg1",
		"cluster1",
		"391145124054712",
		&ScriptExecutionHistoryPromoteOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestOperations_List(t *testing.T) {
	t.Skip("Warning: No test steps for this operation!")
}

func TestVirtualMachines_ListHosts(t *testing.T) {
	// From example Get All hosts in the cluster
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewVirtualMachinesClient(con,
		"subid")
	_, err := client.ListHosts(ctx,
		"rg1",
		"cluster1",
		&VirtualMachinesListHostsOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestVirtualMachines_RestartHosts(t *testing.T) {
	// From example Restarts the specified HDInsight cluster hosts.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewVirtualMachinesClient(con,
		"subid")
	poller, err := client.BeginRestartHosts(ctx,
		"rg1",
		"cluster1",
		[]*string{
			to.StringPtr("gateway1"),
			to.StringPtr("gateway3")},
		&VirtualMachinesBeginRestartHostsOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestVirtualMachines_GetAsyncOperationStatus(t *testing.T) {
	// From example Gets the async operation status of restarting host.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewVirtualMachinesClient(con,
		"subid")
	_, err := client.GetAsyncOperationStatus(ctx,
		"rg1",
		"cluster1",
		"CF938302-6B4D-44A0-A6D2-C0D67E847AEC",
		&VirtualMachinesGetAsyncOperationStatusOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestPrivateEndpointConnections_ListByCluster(t *testing.T) {
	// From example Get all private endpoint connections for a specific HDInsight cluster.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewPrivateEndpointConnectionsClient(con,
		"subid")
	pager := client.ListByCluster("rg1",
		"cluster1",
		&PrivateEndpointConnectionsListByClusterOptions{})
	for pager.NextPage(ctx) {
		if err := pager.Err(); err != nil {
			t.Fatalf("failed to advance page: %v", err)
		}
		for _, v := range pager.PageResponse().Value {
			fmt.Printf("PrivateEndpointConnection.ID: %s\n", *v.ID)
			if v.ID == nil {
				t.Fatal("PrivateEndpointConnection.ID should not be nil!")
			}
		}
	}
}

func TestPrivateEndpointConnections_CreateOrUpdate(t *testing.T) {
	// From example Approve a private endpoint connection manually.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewPrivateEndpointConnectionsClient(con,
		"subid")
	poller, err := client.BeginCreateOrUpdate(ctx,
		"rg1",
		"cluster1",
		"testprivateep.b3bf5fed-9b12-4560-b7d0-2abe1bba07e2",
		PrivateEndpointConnection{
			Properties: &PrivateEndpointConnectionProperties{
				PrivateLinkServiceConnectionState: &PrivateLinkServiceConnectionState{
					Description:     to.StringPtr("update it from pending to approved."),
					ActionsRequired: to.StringPtr("None"),
					Status:          PrivateLinkServiceConnectionStatusApproved.ToPtr(),
				},
			},
		},
		&PrivateEndpointConnectionsBeginCreateOrUpdateOptions{})
	if err != nil {
		t.Fatal(err)
	}
	res, err := poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
	if res.PrivateEndpointConnection.ID == nil {
		t.Fatal("PrivateEndpointConnection.ID should not be nil!")
	}
}

func TestPrivateEndpointConnections_Get(t *testing.T) {
	// From example Get specific private endpoint connection for a specific HDInsight cluster.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewPrivateEndpointConnectionsClient(con,
		"subid")
	res, err := client.Get(ctx,
		"rg1",
		"cluster1",
		"testprivateep.b3bf5fed-9b12-4560-b7d0-2abe1bba07e2",
		&PrivateEndpointConnectionsGetOptions{})
	if err != nil {
		t.Fatal(err)
	}
	if res.PrivateEndpointConnection.ID == nil {
		t.Fatal("PrivateEndpointConnection.ID should not be nil!")
	}
}

func TestPrivateEndpointConnections_Delete(t *testing.T) {
	// From example Delete specific private endpoint connection for a specific HDInsight cluster.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewPrivateEndpointConnectionsClient(con,
		"subid")
	poller, err := client.BeginDelete(ctx,
		"rg1",
		"cluster1",
		"testprivateep.b3bf5fed-9b12-4560-b7d0-2abe1bba07e2",
		&PrivateEndpointConnectionsBeginDeleteOptions{})
	if err != nil {
		t.Fatal(err)
	}
	_, err = poller.PollUntilDone(ctx, 30*time.Second)
	if err != nil {
		t.Fatal(err)
	}
}

func TestPrivateLinkResources_ListByCluster(t *testing.T) {
	// From example Get all private link resources in a specific HDInsight cluster.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewPrivateLinkResourcesClient(con,
		"subid")
	_, err := client.ListByCluster(ctx,
		"rg1",
		"cluster1",
		&PrivateLinkResourcesListByClusterOptions{})
	if err != nil {
		t.Fatal(err)
	}
}

func TestPrivateLinkResources_Get(t *testing.T) {
	// From example Get specific private link resource in a specific HDInsight cluster.
	defer func() {
		if r := recover(); r != nil {
			t.Fatal("stacktrace from panic: \n" + string(debug.Stack()))
		}
	}()
	client := NewPrivateLinkResourcesClient(con,
		"subid")
	res, err := client.Get(ctx,
		"rg1",
		"cluster1",
		"gateway",
		&PrivateLinkResourcesGetOptions{})
	if err != nil {
		t.Fatal(err)
	}
	if res.PrivateLinkResource.ID == nil {
		t.Fatal("PrivateLinkResource.ID should not be nil!")
	}
}

// TestMain will exec each test
func TestMain(m *testing.M) {
	setUp()
	retCode := m.Run() // exec test and this returns an exit code to pass to os
	tearDown()
	os.Exit(retCode)
}

func getEnv(key, fallback string) string {
	if value, ok := os.LookupEnv(key); ok {
		return value
	}
	return fallback
}

func setUp() {
	ctx = context.Background()
	subscriptionId = getEnv("SUBSCRIPTION_ID", "00000000-0000-0000-0000-000000000000")
	mockHost = getEnv("AZURE_VIRTUAL_SERVER_HOST", "https://localhost:8443")

	tr := &http.Transport{}
	if err := http2.ConfigureTransport(tr); err != nil {
		fmt.Printf("Failed to configure http2 transport: %v", err)
	}
	tr.TLSClientConfig.InsecureSkipVerify = true
	client := &http.Client{Transport: tr}
	cred, err = azidentity.NewEnvironmentCredential(&azidentity.EnvironmentCredentialOptions{AuthorityHost: mockHost, HTTPClient: client})
	if err != nil {
		panic(err)
	}

	con = arm.NewConnection(mockHost, cred, &arm.ConnectionOptions{
		Logging: policy.LogOptions{
			IncludeBody: true,
		},
		HTTPClient: client,
	})
}

func tearDown() {

}
